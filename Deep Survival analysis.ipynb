{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Deep Survival analysis.ipynb","provenance":[],"authorship_tag":"ABX9TyMDGzWxTfiYy40pfkuCz+45"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"TBLdrRJEbXGL","colab_type":"text"},"source":["## **The block below shows the DeepSurv_logger**"]},{"cell_type":"code","metadata":{"id":"yn94VCgFa7Kp","colab_type":"code","colab":{}},"source":["import logging\n","import tensorboard_logger \n","from collections import defaultdict\n","import sys\n","import math\n","\n","class DeepSurvLogger():\n","    def __init__(self, name):\n","        self.logger         = logging.getLogger(name)\n","        self.history = {}\n","\n","    def logMessage(self,message):\n","        self.logger.info(message)\n","\n","    def print_progress_bar(self, step, max_steps, loss = None, ci = None, bar_length = 25, char = '*'):\n","        progress_length = int(bar_length * step / max_steps)\n","        progress_bar = [char] * (progress_length) + [' '] * (bar_length - progress_length)\n","        space_padding = int(math.log10(max_steps))\n","        if step > 0:\n","            space_padding -= int(math.log10(step))\n","        space_padding = ''.join([' '] * space_padding)\n","        message = \"Training step %d/%d %s|\" % (step, max_steps, space_padding) + ''.join(progress_bar) + \"|\"\n","        if loss:\n","            message += \" - loss: %.4f\" % loss\n","        if ci:\n","            message += \" - ci: %.4f\" % ci\n","\n","        self.logger.info(message)\n","\n","    def logValue(self, key, value, step):\n","        pass\n","\n","    def shutdown(self):\n","        logging.shutdown()\n","\n","class TensorboardLogger(DeepSurvLogger):\n","    def __init__(self, name, logdir, max_steps = None, update_freq = 10):\n","        self.max_steps = max_steps\n","\n","        self.logger         = logging.getLogger(name)\n","        self.logger.setLevel(logging.DEBUG)\n","        ch = logging.StreamHandler(sys.stdout)\n","        format = logging.Formatter(\"%(asctime)s - %(message)s\")\n","        ch.setFormatter(format)\n","        self.logger.addHandler(ch)\n","\n","        self.update_freq    = update_freq\n","\n","        self.tb_logger = tensorboard_logger.Logger(logdir)\n","\n","        self.history = defaultdict(list)\n","\n","    def logValue(self, key, value, step):\n","        self.tb_logger.log_value(key, value, step)\n","        self.history[key].append((step, value))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"hi8eCJ7JbIKr","colab_type":"code","outputId":"2435a645-d15a-404d-acfa-d2ecad322bc9","executionInfo":{"status":"ok","timestamp":1587316310788,"user_tz":-180,"elapsed":8918,"user":{"displayName":"Enas Kh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiPU_yzzuoQ9cZVtCSj33xZH-htzOgDNBv0_7woeQ=s64","userId":"14585450817422253727"}},"colab":{"base_uri":"https://localhost:8080/","height":204}},"source":["!pip install tensorboard_logger "],"execution_count":0,"outputs":[{"output_type":"stream","text":["Collecting tensorboard_logger\n","  Downloading https://files.pythonhosted.org/packages/87/7a/ec0fd26dba69191f82eb8f38f5b401c124f45a207490a7ade6ea9717ecdb/tensorboard_logger-0.1.0-py2.py3-none-any.whl\n","Requirement already satisfied: protobuf in /usr/local/lib/python3.6/dist-packages (from tensorboard_logger) (3.10.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from tensorboard_logger) (1.12.0)\n","Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard_logger) (1.4.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from tensorboard_logger) (1.18.2)\n","Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard_logger) (7.0.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf->tensorboard_logger) (46.1.3)\n","Installing collected packages: tensorboard-logger\n","Successfully installed tensorboard-logger-0.1.0\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"IbrGTjeMbqnG","colab_type":"text"},"source":["## **Utility functions for running DeepSurv experiments**"]},{"cell_type":"code","metadata":{"id":"VRi9RKQhbQCM","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"H0mjPZ5WcHQR","colab_type":"code","outputId":"e62d9628-fe54-46eb-f77a-1cddea2fbf46","executionInfo":{"status":"ok","timestamp":1587316568965,"user_tz":-180,"elapsed":7148,"user":{"displayName":"Enas Kh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiPU_yzzuoQ9cZVtCSj33xZH-htzOgDNBv0_7woeQ=s64","userId":"14585450817422253727"}},"colab":{"base_uri":"https://localhost:8080/","height":201}},"source":["!pip install lasagne"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Collecting lasagne\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/98/bf/4b2336e4dbc8c8859c4dd81b1cff18eef2066b4973a1bd2b0ca2e5435f35/Lasagne-0.1.tar.gz (125kB)\n","\r\u001b[K     |██▋                             | 10kB 17.9MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 20kB 1.7MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 30kB 2.5MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 40kB 3.3MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 51kB 2.1MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 61kB 2.5MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 71kB 2.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 81kB 3.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 92kB 2.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 102kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 112kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 122kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 133kB 2.7MB/s \n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from lasagne) (1.18.2)\n","Building wheels for collected packages: lasagne\n","  Building wheel for lasagne (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for lasagne: filename=Lasagne-0.1-cp36-none-any.whl size=79275 sha256=154ff8bf9cd00a171130835224ea3acbb8256e3b66cd18ecd1ff0f2fa40cce49\n","  Stored in directory: /root/.cache/pip/wheels/a5/8e/31/b4cae7e5507f8582e77d7f5cf2815be8820ccacfa0519ca60c\n","Successfully built lasagne\n","Installing collected packages: lasagne\n","Successfully installed lasagne-0.1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"70ff5tFycScF","colab_type":"code","outputId":"c469de37-1a88-421c-eeae-ef16faa19314","executionInfo":{"status":"ok","timestamp":1587316930094,"user_tz":-180,"elapsed":4657,"user":{"displayName":"Enas Kh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiPU_yzzuoQ9cZVtCSj33xZH-htzOgDNBv0_7woeQ=s64","userId":"14585450817422253727"}},"colab":{"base_uri":"https://localhost:8080/","height":50}},"source":["!pip install downsample"],"execution_count":0,"outputs":[{"output_type":"stream","text":["\u001b[31mERROR: Could not find a version that satisfies the requirement downsample (from versions: none)\u001b[0m\n","\u001b[31mERROR: No matching distribution found for downsample\u001b[0m\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"sIRjWeWQhOmD","colab_type":"code","outputId":"929ecf75-d82a-4eca-f394-2928e394bdd9","executionInfo":{"status":"ok","timestamp":1587317900943,"user_tz":-180,"elapsed":4310,"user":{"displayName":"Enas Kh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiPU_yzzuoQ9cZVtCSj33xZH-htzOgDNBv0_7woeQ=s64","userId":"14585450817422253727"}},"colab":{"base_uri":"https://localhost:8080/","height":50}},"source":["pip install --user downsample"],"execution_count":0,"outputs":[{"output_type":"stream","text":["\u001b[31mERROR: Could not find a version that satisfies the requirement downsample (from versions: none)\u001b[0m\n","\u001b[31mERROR: No matching distribution found for downsample\u001b[0m\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"-CkQZSHker5c","colab_type":"text"},"source":["# Utility functions for visualizing results of DeepSurv experiments"]},{"cell_type":"code","metadata":{"id":"MhbTjJIQeuI4","colab_type":"code","colab":{}},"source":["import matplotlib\n","import matplotlib.pyplot as plt\n","from matplotlib.backends.backend_pdf import PdfPages\n","import pylab\n","\n","import numpy as np\n","\n","import os\n","\n","from lifelines import KaplanMeierFitter\n","from lifelines.statistics import logrank_test\n","\n","def extract_value_list(arr):\n","    return list(np.array(arr)[:,1])\n","\n","def plot_log(log):\n","    \"\"\"\n","    Plots the training and validation curves for a network's loss function\n","    and calculated concordance index.\n","\n","    Parameters:\n","        log: a dictionary with a list of values for any of the following keys:\n","            'train': training loss\n","            'valid': validation loss\n","            'train_ci': training concordance index\n","            VALID_CI: validation concordance index\n","    \"\"\"\n","    TRAIN_LOSS = 'loss'\n","    TRAIN_CI = 'c-index'\n","    VALID_LOSS = 'valid_loss'\n","    VALID_CI = 'valid_c-index'\n","\n","    num_epochs = len(log[TRAIN_LOSS])\n","\n","    # Plots Negative Log Likelihood vs. Epoch\n","    fig, ax1 = plt.subplots()\n","    # plt.figure()\n","    handles = []\n","    if TRAIN_LOSS in log:\n","        epochs = range(num_epochs)\n","        values = extract_value_list(log[TRAIN_LOSS])\n","        train, = ax1.plot(epochs, values, 'b', label = 'Training')\n","        ax1.tick_params('y', colors='b')\n","        handles.append(train)\n","    if VALID_LOSS in log:\n","        ax2 = ax1.twinx()\n","        epochs = np.linspace(0,num_epochs-1,num=len(log[VALID_LOSS]))\n","        values = extract_value_list(log[VALID_LOSS])\n","        valid, = ax2.plot(epochs,values, 'r', label = 'Validation')\n","        ax2.tick_params('y', colors='r')\n","        handles.append(valid)\n","    plt.xlabel('Epoch')\n","    plt.ylabel('Negative Log Likelihood')\n","    plt.legend(handles=handles, loc = 0)\n","\n","    # Plots Concordance Index vs. Epoch\n","    plt.figure()\n","    handles = []\n","    if TRAIN_CI in log:\n","        epochs = np.linspace(0,num_epochs-1,num=len(log[TRAIN_CI]))\n","        train, = plt.plot(epochs, extract_value_list(log[TRAIN_CI]), label = 'Training')\n","        handles.append(train)\n","    if VALID_CI in log:\n","        epochs = np.linspace(0,num_epochs-1,num=len(log[VALID_CI]))\n","        valid, = plt.plot(epochs, extract_value_list(log[VALID_CI]), label = 'Validation')\n","        handles.append(valid)\n","    plt.xlabel('Epoch')\n","    plt.ylabel('Concordance Index')\n","    plt.legend(handles = handles, loc = 4)\n","\n","def plot_risk_model(x_0, x_1, hr, figsize=(4,3), clim = (-3,3), cmap = 'jet'):\n","    fig, ax = plt.subplots(figsize=figsize)\n","    plt.xlim(-1, 1)\n","    plt.xlabel('$x_0$', fontsize='large')\n","    plt.xticks(np.arange(-1, 1.5, .5))\n","\n","    plt.ylim(-1, 1)\n","    plt.ylabel('$x_1$', fontsize='large')\n","    plt.yticks(np.arange(-1, 1.5, .5))\n","    \n","    im = plt.scatter(x=x_0, y=x_1, c=hr, marker='.', cmap=cmap)\n","    fig.colorbar(im)\n","    # plt.clim(0, 1)\n","    plt.clim(*clim)\n","    plt.tight_layout()\n","    return (fig, ax, im)\n","\n","def save_fig(fig, fp):\n","    # TODO fit the pdf saving cutting off the x and y axis labels\n","    pp_true = PdfPages(fp)\n","    pp_true.savefig(fig, dpi=600)\n","    pp_true.close()\n","\n","def plot_experiment_scatters(risk_fxn, dataset, norm_vals = None, output_file=None, \n","    figsize = (4,3), clim=(-3,3), cmap = 'jet', plot_error=False, trt_idx = None):\n","    \n","    def norm_hr(hr):\n","        # return hr\n","        return hr - hr.mean();\n","        # return (hr - hr.min()) / (hr.max() - hr.min())\n","\n","    x_0 = dataset['x'][:, 0]\n","    x_1 = dataset['x'][:, 1]\n","\n","    # Plot model predictions\n","    x = dataset['x']\n","    if norm_vals:\n","        x = (x - norm_vals['mean']) / norm_vals['std']\n","\n","    (head, tail) = os.path.split(output_file)\n","\n","    if not trt_idx is None:\n","        trt_values = np.unique(x[:,trt_idx])\n","        for (idx,trt_value) in enumerate(trt_values):\n","            x_trt = np.copy(x)\n","            x_trt[:,trt_idx] = trt_value\n","            hr_trt = risk_fxn(x_trt)\n","            hr_trt = norm_hr(hr_trt)\n","            fig_trt, _, _ = plot_risk_model(x_0, x_1, hr_trt, figsize, clim, cmap)\n","\n","            if output_file:\n","                save_fig(fig_trt, os.path.join(head, \"treatment_%d_\" % idx + tail))\n","    else:\n","        hr_pred = risk_fxn(x)\n","        hr_pred = norm_hr(hr_pred)\n","        fig_pred, _, _ = plot_risk_model(x_0, x_1, hr_pred, figsize, clim, cmap)\n","\n","        if output_file:\n","            save_fig(fig_pred, os.path.join(head, \"pred_\" + tail))\n","\n","    if 'hr' in dataset:\n","        hr_true = dataset['hr']\n","        hr_true = norm_hr(hr_true)\n","        fig_true, _, _ = plot_risk_model(x_0, x_1, hr_true, figsize, clim, cmap)\n","\n","        if output_file:\n","            save_fig(fig_true, os.path.join(head, \"true_\" + tail))\n","\n","        if plot_error:\n","            hr_error = np.abs(hr_true - hr_pred)\n","            fig_error, _, _ = plot_risk_model(x_0, x_1, hr_error, figsize, clim=(0,20), cmap = cmap)\n","\n","            if output_file:\n","                save_fig(fig_error, os.path.join(head, \"error_\" + tail))\n","\n","def plot_survival_curves(rec_t, rec_e, antirec_t, antirec_e, experiment_name = '', output_file = None):\n","    # Set-up plots\n","    plt.figure(figsize=(12,3))\n","    ax = plt.subplot(111)\n","\n","    # Fit survival curves\n","    kmf = KaplanMeierFitter()\n","    kmf.fit(rec_t, event_observed=rec_e, label=' '.join([experiment_name, \"Recommendation\"]))   \n","    kmf.plot(ax=ax,linestyle=\"-\")\n","    kmf.fit(antirec_t, event_observed=antirec_e, label=' '.join([experiment_name, \"Anti-Recommendation\"]))\n","    kmf.plot(ax=ax,linestyle=\"--\")\n","    \n","    # Format graph\n","    plt.ylim(0,1);\n","    ax.set_xlabel('Timeline (months)',fontsize='large')\n","    ax.set_ylabel('Percentage of Population Alive',fontsize='large')\n","    \n","    # Calculate p-value\n","    results = logrank_test(rec_t, antirec_t, rec_e, antirec_e, alpha=.95)\n","    results.print_summary()\n","\n","    # Location the label at the 1st out of 9 tick marks\n","    xloc = max(np.max(rec_t),np.max(antirec_t)) / 9\n","    if results.p_value < 1e-5:\n","        ax.text(xloc,.2,'$p < 1\\mathrm{e}{-5}$',fontsize=20)\n","    else:\n","        ax.text(xloc,.2,'$p=%f$' % results.p_value,fontsize=20)\n","    plt.legend(loc='best',prop={'size':15})\n","\n","\n","    if output_file:\n","        plt.tight_layout()\n","        pylab.savefig(output_file)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"wCkEdhoofAxN","colab_type":"code","outputId":"c31d2659-a3b3-49da-863e-2ab50c2f9f01","executionInfo":{"status":"ok","timestamp":1587317326611,"user_tz":-180,"elapsed":5806,"user":{"displayName":"Enas Kh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiPU_yzzuoQ9cZVtCSj33xZH-htzOgDNBv0_7woeQ=s64","userId":"14585450817422253727"}},"colab":{"base_uri":"https://localhost:8080/","height":334}},"source":["!pip install lifelines"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Collecting lifelines\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/33/17/1ec11540461df101690d4918aab29374a61c08df2a755b6cfec382e4dd98/lifelines-0.24.4-py3-none-any.whl (325kB)\n","\u001b[K     |████████████████████████████████| 327kB 2.6MB/s \n","\u001b[?25hRequirement already satisfied: pandas>=0.23.0 in /usr/local/lib/python3.6/dist-packages (from lifelines) (1.0.3)\n","Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.6/dist-packages (from lifelines) (1.4.1)\n","Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from lifelines) (1.18.2)\n","Collecting autograd-gamma>=0.3\n","  Downloading https://files.pythonhosted.org/packages/0a/07/d99339c9420b58b723a9189d1373e5c3889758b2202a1a7fe4a3b7a10c5a/autograd_gamma-0.4.2-py2.py3-none-any.whl\n","Requirement already satisfied: autograd>=1.3 in /usr/local/lib/python3.6/dist-packages (from lifelines) (1.3)\n","Requirement already satisfied: matplotlib>=3.0 in /usr/local/lib/python3.6/dist-packages (from lifelines) (3.2.1)\n","Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.23.0->lifelines) (2.8.1)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.23.0->lifelines) (2018.9)\n","Requirement already satisfied: future>=0.15.2 in /usr/local/lib/python3.6/dist-packages (from autograd>=1.3->lifelines) (0.16.0)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=3.0->lifelines) (2.4.7)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=3.0->lifelines) (0.10.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=3.0->lifelines) (1.2.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.6.1->pandas>=0.23.0->lifelines) (1.12.0)\n","Installing collected packages: autograd-gamma, lifelines\n","Successfully installed autograd-gamma-0.4.2 lifelines-0.24.4\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"xIRhrcQWfuqn","colab_type":"text"},"source":["### DataSet Exploration"]},{"cell_type":"code","metadata":{"id":"H_BoLM7mfKP1","colab_type":"code","colab":{}},"source":["from math import log, exp\n","import numpy as np\n","\n","class SimulatedData:\n","    def __init__(self, hr_ratio,\n","        average_death = 5,\n","        censor_mode = 'end_time', end_time = 15, observed_p = None,\n","        num_features = 10, num_var = 2,\n","        treatment_group = False):\n","        \"\"\"\n","        Factory class for producing simulated survival data.\n","        Current supports two forms of simulated data:\n","            Linear:\n","                Where risk is a linear combination of an observation's features\n","            Nonlinear (Gaussian):\n","                A gaussian combination of covariates\n","\n","        Parameters:\n","            hr_ratio: lambda_max hazard ratio.\n","            average_death: average death time that is the mean of the\n","                Exponentional distribution.\n","            censor_mode: the method to calculate whether a patient is censored.\n","                Options: ['end_time', 'observed_p']\n","                'end_time': requires the parameter end_time, which is used to censor any patient with death_time > end_time\n","                'observed_p': requires the parammeter observed_p, which is the percentage of patients with observed death times\n","            end_time: censoring time that represents an 'end of study'. Any death\n","                time greater than end_time will be censored.\n","            num_features: size of observation vector. Default: 10.\n","            num_var: number of varaibles simulated data depends on. Default: 2.\n","            treatment_group: True or False. Include an additional covariate\n","                representing a binary treatment group.\n","        \"\"\"\n","\n","        self.hr_ratio = hr_ratio\n","        self.censor_mode = censor_mode\n","        self.end_time = end_time\n","        self.observed_p = observed_p\n","        self.average_death = average_death\n","        self.treatment_group = treatment_group\n","        self.m = int(num_features) + int(treatment_group)\n","        self.num_var = num_var\n","\n","    def _linear_H(self,x):\n","        \"\"\"\n","        Calculates a linear combination of x's features.\n","        Coefficients are 1, 2, ..., self.num_var, 0,..0]\n","\n","        Parameters:\n","            x: (n,m) numpy array of observations\n","\n","        Returns:\n","            risk: the calculated linear risk for a set of data x\n","        \"\"\"\n","        # Make the coefficients [1,2,...,num_var,0,..0]\n","        b = np.zeros((self.m,))\n","        b[0:self.num_var] = range(1,self.num_var + 1)\n","\n","        # Linear Combinations of Coefficients and Covariates\n","        risk = np.dot(x, b)\n","        return risk\n","\n","    def _gaussian_H(self,x,\n","        c= 0.0, rad= 0.5):\n","        \"\"\"\n","        Calculates the Gaussian function of a subset of x's features.\n","\n","        Parameters:\n","            x: (n, m) numpy array of observations.\n","            c: offset of Gaussian function. Default: 0.0.\n","            r: Gaussian scale parameter. Default: 0.5.\n","\n","        Returns:\n","            risk: the calculated Gaussian risk for a set of data x\n","        \"\"\"\n","        max_hr, min_hr = log(self.hr_ratio), log(1.0 / self.hr_ratio)\n","\n","        # Z = ( (x_0 - c)^2 + (x_1 - c)^2 + ... + (x_{num_var} - c)^2)\n","        z = np.square((x - c))\n","        z = np.sum(z[:,0:self.num_var], axis = -1)\n","\n","        # Compute Gaussian\n","        risk = max_hr * (np.exp(-(z) / (2 * rad ** 2)))\n","        return risk\n","\n","    def generate_data(self, N,\n","        method = 'gaussian', gaussian_config = {},\n","        **kwargs):\n","        \"\"\"\n","        Generates a set of observations according to an exponentional Cox model.\n","\n","        Parameters:\n","            N: the number of observations.\n","            method: the type of simulated data. 'linear' or 'gaussian'.\n","            guassian_config: dictionary of additional parameters for gaussian\n","                simulation.\n","\n","        Returns:\n","            dataset: a dictionary object with the following keys:\n","                'x' : (N,m) numpy array of observations.\n","                't' : (N) numpy array of observed time events.\n","                'e' : (N) numpy array of observed time intervals.\n","                'hr': (N) numpy array of observed true risk.\n","\n","        See:\n","        Peter C Austin. Generating survival times to simulate cox proportional\n","        hazards models with time-varying covariates. Statistics in medicine,\n","        31(29):3946-3958, 2012.\n","        \"\"\"\n","\n","        # Patient Baseline information\n","        data = np.random.uniform(low= -1, high= 1,\n","            size = (N,self.m))\n","\n","        if self.treatment_group:\n","            data[:,-1] = np.squeeze(np.random.randint(0,2,(N,1)))\n","            print(data[:,-1])\n","\n","        # Each patient has a uniform death probability\n","        p_death = self.average_death * np.ones((N,1))\n","\n","        # Patients Hazard Model\n","        # \\lambda(t|X) = \\lambda_0(t) exp(H(x))\n","        #\n","        # risk = True log hazard ratio\n","        # log(\\lambda(t|X) / \\lambda_0(t)) = H(x)\n","        if method == 'linear':\n","            risk = self._linear_H(data)\n","\n","        elif method == 'gaussian':\n","            risk = self._gaussian_H(data,**gaussian_config)\n","\n","        # Center the hazard ratio so population dies at the same rate\n","        # independent of control group (makes the problem easier)\n","        risk = risk - np.mean(risk)\n","\n","        # Generate time of death for each patient\n","        # currently exponential random variable\n","        death_time = np.zeros((N,1))\n","        for i in range(N):\n","            if self.treatment_group and data[i,-1] == 0:\n","                death_time[i] = np.random.exponential(p_death[i])\n","            else:\n","                death_time[i] = np.random.exponential(p_death[i]) / exp(risk[i])\n","\n","        # If Censor_mode is 'observed_p': then find the end time in which observed_p percent of patients have an observed death\n","        if self.censor_mode is 'observed_p':\n","            if self.observed_p is None:\n","                raise ValueError(\"Parameter observed_p must be porivded if censor_mode is configured to 'observed_p'\")\n","            end_time_idx = int(N * self.observed_p)\n","            self.end_time = np.sort(death_time.flatten())[end_time_idx]\n","\n","        # Censor anything that is past end time\n","        censoring = np.ones((N,1))\n","        death_time[death_time > self.end_time] = self.end_time\n","        censoring[death_time == self.end_time] = 0\n","\n","        # Flatten Arrays to Vectors\n","        death_time = np.squeeze(death_time)\n","        censoring = np.squeeze(censoring)\n","\n","        dataset = {\n","            'x' : data.astype(np.float32),\n","            'e' : censoring.astype(np.int32),\n","            't' : death_time.astype(np.float32),\n","            'hr' : risk.astype(np.float32)\n","        }\n","\n","        return dataset\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Beae62_Gl6EJ","colab_type":"code","outputId":"00909d30-1731-47cf-f054-9b332d50dcbe","executionInfo":{"status":"ok","timestamp":1587319233609,"user_tz":-180,"elapsed":3787,"user":{"displayName":"Enas Kh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiPU_yzzuoQ9cZVtCSj33xZH-htzOgDNBv0_7woeQ=s64","userId":"14585450817422253727"}},"colab":{"base_uri":"https://localhost:8080/","height":50}},"source":["!pip install collections"],"execution_count":0,"outputs":[{"output_type":"stream","text":["\u001b[31mERROR: Could not find a version that satisfies the requirement collections (from versions: none)\u001b[0m\n","\u001b[31mERROR: No matching distribution found for collections\u001b[0m\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"lJwbgKLDl8vx","colab_type":"code","outputId":"00491a48-fae8-46c6-fece-ca572197710f","executionInfo":{"status":"ok","timestamp":1587319283359,"user_tz":-180,"elapsed":4450,"user":{"displayName":"Enas Kh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiPU_yzzuoQ9cZVtCSj33xZH-htzOgDNBv0_7woeQ=s64","userId":"14585450817422253727"}},"colab":{"base_uri":"https://localhost:8080/","height":50}},"source":["!pip install lasagne"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: lasagne in /usr/local/lib/python3.6/dist-packages (0.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from lasagne) (1.18.2)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"IWD8STLMl93p","colab_type":"code","colab":{}},"source":["!pip install"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"PjoBjbetgRFw","colab_type":"code","outputId":"cf1613bd-2fb1-4223-c0e6-01cf886ab23b","executionInfo":{"status":"error","timestamp":1587320065965,"user_tz":-180,"elapsed":2254,"user":{"displayName":"Enas Kh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiPU_yzzuoQ9cZVtCSj33xZH-htzOgDNBv0_7woeQ=s64","userId":"14585450817422253727"}},"colab":{"base_uri":"https://localhost:8080/","height":503}},"source":["import h5py\n","import scipy.stats as st\n","from collections import defaultdict\n","import numpy as np\n","import pandas as pd\n","import copy\n","\n","import lasagne\n","\n","def load_datasets(dataset_file):\n","    datasets = defaultdict(dict)\n","\n","    with h5py.File(dataset_file, 'r') as fp:\n","        for ds in fp:\n","            for array in fp[ds]:\n","                datasets[ds][array] = fp[ds][array][:]\n","\n","    return datasets\n","\n","def format_dataset_to_df(dataset, duration_col, event_col, trt_idx = None):\n","    xdf = pd.DataFrame(dataset['x'])\n","    if trt_idx is not None:\n","        xdf = xdf.rename(columns={trt_idx : 'treat'})\n","\n","    dt = pd.DataFrame(dataset['t'], columns=[duration_col])\n","    censor = pd.DataFrame(dataset['e'], columns=[event_col])\n","    cdf = pd.concat([xdf, dt, censor], axis=1)\n","    return cdf\n","\n","def standardize_dataset(dataset, offset, scale):\n","    norm_ds = copy.deepcopy(dataset)\n","    norm_ds['x'] = (norm_ds['x'] - offset) / scale\n","    return norm_ds\n","\n","def bootstrap_metric(metric_fxn, dataset, N=100):\n","    def sample_dataset(dataset, sample_idx):\n","        sampled_dataset = {}\n","        for (key,value) in dataset.items():\n","            sampled_dataset[key] = value[sample_idx]\n","        return sampled_dataset\n","\n","    metrics = []\n","    size = len(dataset['x'])\n","\n","    for _ in range(N):\n","        resample_idx = np.random.choice(size, size=size, replace = True)\n","    \n","        metric = metric_fxn(**sample_dataset(dataset, resample_idx))\n","        metrics.append(metric)\n","    \n","    # Find mean and 95% confidence interval\n","    mean = np.mean(metrics)\n","    conf_interval = st.t.interval(0.95, len(metrics)-1, loc=mean, scale=st.sem(metrics))\n","    return {\n","        'mean': mean,\n","        'confidence_interval': conf_interval\n","    }\n","\n","def get_optimizer_from_str(update_fn):\n","    if update_fn == 'sgd':\n","        return lasagne.updates.sgd\n","    elif update_fn == 'adam':\n","        return lasagne.updates.adam\n","    elif update_fn == 'rmsprop':\n","        return lasagne.updates.rmsprop\n","\n","    return None\n","\n","def calculate_recs_and_antirecs(rec_trt, true_trt, dataset, print_metrics=True):\n","    if isinstance(true_trt, int):\n","        true_trt = dataset['x'][:,true_trt]\n","\n","    # trt_values = zip([0,1],np.sort(np.unique(true_trt)))\n","    trt_values = enumerate(np.sort(np.unique(true_trt)))\n","    equal_trt = [np.logical_and(rec_trt == rec_value, true_trt == true_value) for (rec_value, true_value) in trt_values]\n","    rec_idx = np.logical_or(*equal_trt)\n","    # original Logic\n","    # rec_idx = np.logical_or(np.logical_and(rec_trt == 1,true_trt == 1),\n","    #               np.logical_and(rec_trt == 0,true_trt == 0))\n","\n","    rec_t = dataset['t'][rec_idx]\n","    antirec_t = dataset['t'][~rec_idx]\n","    rec_e = dataset['e'][rec_idx]\n","    antirec_e = dataset['e'][~rec_idx]\n","\n","    if print_metrics:\n","        print(\"Printing treatment recommendation metrics\")\n","        metrics = {\n","            'rec_median' : np.median(rec_t),\n","            'antirec_median' : np.median(antirec_t)\n","        }\n","        print(\"Recommendation metrics:\", metrics)\n","\n","    return {\n","        'rec_t' : rec_t, \n","        'rec_e' : rec_e, \n","        'antirec_t' : antirec_t, \n","        'antirec_e' : antirec_e\n","    }\n"],"execution_count":0,"outputs":[{"output_type":"error","ename":"ImportError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)","\u001b[0;32m<ipython-input-34-e400b81e0992>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mlasagne\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_datasets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/lasagne/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnonlinearities\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0minit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mobjectives\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/lasagne/layers/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mnoise\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mconv\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mpool\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/lasagne/layers/pool.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mas_tuple\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtheano\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignal\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdownsample\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mImportError\u001b[0m: cannot import name 'downsample'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"]}]},{"cell_type":"code","metadata":{"id":"VPPWX4OtjY5Z","colab_type":"code","outputId":"d4ac019e-b612-4168-ac57-30930f88ef55","executionInfo":{"status":"ok","timestamp":1587318480263,"user_tz":-180,"elapsed":4751,"user":{"displayName":"Enas Kh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiPU_yzzuoQ9cZVtCSj33xZH-htzOgDNBv0_7woeQ=s64","userId":"14585450817422253727"}},"colab":{"base_uri":"https://localhost:8080/","height":84}},"source":["!pip install theano"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: theano in /usr/local/lib/python3.6/dist-packages (1.0.4)\n","Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from theano) (1.4.1)\n","Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from theano) (1.18.2)\n","Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from theano) (1.12.0)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"BpLRjrP7jh02","colab_type":"code","outputId":"abd9fdf7-a799-451b-efa6-6713fc070394","executionInfo":{"status":"ok","timestamp":1587318526474,"user_tz":-180,"elapsed":16258,"user":{"displayName":"Enas Kh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiPU_yzzuoQ9cZVtCSj33xZH-htzOgDNBv0_7woeQ=s64","userId":"14585450817422253727"}},"colab":{"base_uri":"https://localhost:8080/","height":906}},"source":["!pip install tensor"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Collecting tensor\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ed/87/796821bf9579557a5baac1c01c42bd56e3be47bdaf131779ccdd953f1c80/tensor-0.3.6.tar.gz (50kB)\n","\u001b[K     |████████████████████████████████| 51kB 1.6MB/s \n","\u001b[?25hCollecting Twisted\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b7/04/1a664c9e5ec0224a1c1a154ddecaa4dc7b8967521bba225efcc41a03d5f3/Twisted-20.3.0-cp36-cp36m-manylinux1_x86_64.whl (3.1MB)\n","\u001b[K     |████████████████████████████████| 3.1MB 6.0MB/s \n","\u001b[?25hRequirement already satisfied: PyYaml in /usr/local/lib/python3.6/dist-packages (from tensor) (3.13)\n","Requirement already satisfied: protobuf in /usr/local/lib/python3.6/dist-packages (from tensor) (3.10.0)\n","Collecting construct\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/00/e0/71e41b817220333c7c511c3f78d988d69f9b03b5cca2f251a898ad3567a3/construct-2.10.56.tar.gz (54kB)\n","\u001b[K     |████████████████████████████████| 61kB 7.8MB/s \n","\u001b[?25hCollecting pysnmp\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/25/7e/1e17facea54dd21c6a72db6ae57a5bfdd56edd54b8c4850668b554bdddba/pysnmp-4.4.12-py2.py3-none-any.whl (296kB)\n","\u001b[K     |████████████████████████████████| 296kB 39.4MB/s \n","\u001b[?25hRequirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.6/dist-packages (from Twisted->tensor) (19.3.0)\n","Collecting Automat>=0.3.0\n","  Downloading https://files.pythonhosted.org/packages/dd/83/5f6f3c1a562674d65efc320257bdc0873ec53147835aeef7762fe7585273/Automat-20.2.0-py2.py3-none-any.whl\n","Collecting zope.interface>=4.4.2\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/57/33/565274c28a11af60b7cfc0519d46bde4125fcd7d32ebc0a81b480d0e8da6/zope.interface-5.1.0-cp36-cp36m-manylinux2010_x86_64.whl (234kB)\n","\u001b[K     |████████████████████████████████| 235kB 46.3MB/s \n","\u001b[?25hCollecting PyHamcrest!=1.10.0,>=1.9.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/40/16/e54cc65891f01cb62893540f44ffd3e8dab0a22443e1b438f1a9f5574bee/PyHamcrest-2.0.2-py3-none-any.whl (52kB)\n","\u001b[K     |████████████████████████████████| 61kB 7.6MB/s \n","\u001b[?25hCollecting hyperlink>=17.1.1\n","  Downloading https://files.pythonhosted.org/packages/7f/91/e916ca10a2de1cb7101a9b24da546fb90ee14629e23160086cf3361c4fb8/hyperlink-19.0.0-py2.py3-none-any.whl\n","Collecting incremental>=16.10.1\n","  Downloading https://files.pythonhosted.org/packages/f5/1d/c98a587dc06e107115cf4a58b49de20b19222c83d75335a192052af4c4b7/incremental-17.5.0-py2.py3-none-any.whl\n","Collecting constantly>=15.1\n","  Downloading https://files.pythonhosted.org/packages/b9/65/48c1909d0c0aeae6c10213340ce682db01b48ea900a7d9fce7a7910ff318/constantly-15.1.0-py2.py3-none-any.whl\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf->tensor) (46.1.3)\n","Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.6/dist-packages (from protobuf->tensor) (1.12.0)\n","Requirement already satisfied: pyasn1>=0.2.3 in /usr/local/lib/python3.6/dist-packages (from pysnmp->tensor) (0.4.8)\n","Collecting pysmi\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1f/fc/02361d1c2b247de73070c457c4da98c448693154894c14f2d7b48dfabf7e/pysmi-0.3.4-py2.py3-none-any.whl (80kB)\n","\u001b[K     |████████████████████████████████| 81kB 8.6MB/s \n","\u001b[?25hCollecting pycryptodomex\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bc/97/68a589e4913b5081e365920a9303a712ccc1e6f6f30cafba2f1fc3644f5e/pycryptodomex-3.9.7-cp36-cp36m-manylinux1_x86_64.whl (13.7MB)\n","\u001b[K     |████████████████████████████████| 13.7MB 311kB/s \n","\u001b[?25hRequirement already satisfied: idna>=2.5 in /usr/local/lib/python3.6/dist-packages (from hyperlink>=17.1.1->Twisted->tensor) (2.8)\n","Collecting ply\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/58/35da89ee790598a0700ea49b2a66594140f44dec458c07e8e3d4979137fc/ply-3.11-py2.py3-none-any.whl (49kB)\n","\u001b[K     |████████████████████████████████| 51kB 6.4MB/s \n","\u001b[?25hBuilding wheels for collected packages: tensor, construct\n","  Building wheel for tensor (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for tensor: filename=tensor-0.3.6-cp36-none-any.whl size=71570 sha256=063d04cb50a2c6a4cae61caa5b63c35c684ab989371c4c19bb7f7855ee8e5539\n","  Stored in directory: /root/.cache/pip/wheels/32/ba/ac/dbd210e9db9e5d549b3d98c57713684c5768298f259b1925ef\n","  Building wheel for construct (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for construct: filename=construct-2.10.56-cp36-none-any.whl size=56878 sha256=dbb24d818fc719abc7b489512fb7b8e69331ff27e1d9d1fe982a407107daecb9\n","  Stored in directory: /root/.cache/pip/wheels/28/7b/bb/5af0216178450142d64876ad635c9e64cb8ac48a584c419214\n","Successfully built tensor construct\n","Installing collected packages: Automat, zope.interface, PyHamcrest, hyperlink, incremental, constantly, Twisted, construct, ply, pysmi, pycryptodomex, pysnmp, tensor\n","Successfully installed Automat-20.2.0 PyHamcrest-2.0.2 Twisted-20.3.0 constantly-15.1.0 construct-2.10.56 hyperlink-19.0.0 incremental-17.5.0 ply-3.11 pycryptodomex-3.9.7 pysmi-0.3.4 pysnmp-4.4.12 tensor-0.3.6 zope.interface-5.1.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"pzcqTP82ni7P","colab_type":"code","outputId":"eae3ca92-8f0e-4e23-f249-1bd674dfe196","executionInfo":{"status":"ok","timestamp":1587322625192,"user_tz":-180,"elapsed":3938,"user":{"displayName":"Enas Kh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiPU_yzzuoQ9cZVtCSj33xZH-htzOgDNBv0_7woeQ=s64","userId":"14585450817422253727"}},"colab":{"base_uri":"https://localhost:8080/","height":50}},"source":["!pip install deep_surv"],"execution_count":37,"outputs":[{"output_type":"stream","text":["\u001b[31mERROR: Could not find a version that satisfies the requirement deep_surv (from versions: none)\u001b[0m\n","\u001b[31mERROR: No matching distribution found for deep_surv\u001b[0m\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"-uzYLeO8k4Qv","colab_type":"code","colab":{}},"source":["from deep_surv import DeepSurv\n","from viz import plot_log\n","#from . import datasets"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"LmRy1kaFwoDp","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}